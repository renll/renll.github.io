---
---

@inproceedings{ren-etal-2021-hyspa,
    title = "{H}y{SPA}: Hybrid Span Generation for Scalable Text-to-Graph Extraction",
    author = "Ren, Liliang  and
      Sun, Chenkai  and
      Ji, Heng  and
      Hockenmaier, Julia",
    journal = {Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
    month = aug,
    year = {2021},
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/2021.findings-acl.356",
    doi = "10.18653/v1/2021.findings-acl.356",
    pages = "4066--4078",
    abbr={ACL Findings},
}

@inproceedings{ren-etal-2019-scalable,
    title = "Scalable and Accurate Dialogue State Tracking via Hierarchical Sequence Generation",
    author = "Ren, Liliang  and
      Ni, Jianmo  and
      McAuley, Julian",
    journal = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
    month = nov,
    year = {2019},
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/D19-1196",
    doi = "10.18653/v1/D19-1196",
    pages = "1876--1885",
    abbr= {EMNLP},
    abstract = "Existing approaches to dialogue state tracking rely on pre-defined ontologies consisting of a set of all possible slot types and values. Though such approaches exhibit promising performance on single-domain benchmarks, they suffer from computational complexity that increases proportionally to the number of pre-defined slots that need tracking. This issue becomes more severe when it comes to multi-domain dialogues which include larger numbers of slots. In this paper, we investigate how to approach DST using a generation framework without the pre-defined ontology list. Given each turn of user utterance and system response, we directly generate a sequence of belief states by applying a hierarchical encoder-decoder structure. In this way, the computational complexity of our model will be a constant regardless of the number of pre-defined slots. Experiments on both the multi-domain and the single domain dialogue state tracking dataset show that our model not only scales easily with the increasing number of pre-defined domains and slots but also reaches the state-of-the-art performance.",
}

@inproceedings{xie-etal-2018-cost,
    title = "Cost-Sensitive Active Learning for Dialogue State Tracking",
    author = "Xie, Kaige  and
      Chang, Cheng  and
      Ren, Liliang  and
      Chen, Lu  and
      Yu, Kai",
    journal = {Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue},
    month = jul,
    year = {2018},
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/W18-5022",
    doi = "10.18653/v1/W18-5022",
    pages = "209--213",
    abbr = {SIGDIAL},
    abstract = "Dialogue state tracking (DST), when formulated as a supervised learning problem, relies on labelled data. Since dialogue state annotation usually requires labelling all turns of a single dialogue and utilizing context information, it is very expensive to annotate all available unlabelled data. In this paper, a novel cost-sensitive active learning framework is proposed based on a set of new dialogue-level query strategies. This is the first attempt to apply active learning for dialogue state tracking. Experiments on DSTC2 show that active learning with mixed data query strategies can effectively achieve the same DST performance with significantly less data annotation compared to traditional training approaches.",
}

@inproceedings{ren-etal-2018-towards,
    title = "Towards Universal Dialogue State Tracking",
    author = "Ren, Liliang  and
      Xie, Kaige  and
      Chen, Lu  and
      Yu, Kai",
    journal = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
    month = oct # "-" # nov,
    year = {2018},
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/D18-1299",
    doi = "10.18653/v1/D18-1299",
    pages = "2780--2786",
    abbr = {EMNLP},
    abstract = "Dialogue state tracker is the core part of a spoken dialogue system. It estimates the beliefs of possible user{'}s goals at every dialogue turn. However, for most current approaches, it{'}s difficult to scale to large dialogue domains. They have one or more of following limitations: (a) Some models don{'}t work in the situation where slot values in ontology changes dynamically; (b) The number of model parameters is proportional to the number of slots; (c) Some models extract features based on hand-crafted lexicons. To tackle these challenges, we propose StateNet, a universal dialogue state tracker. It is independent of the number of values, shares parameters across all slots, and uses pre-trained word vectors instead of explicit semantic dictionaries. Our experiments on two datasets show that our approach not only overcomes the limitations, but also significantly outperforms the performance of state-of-the-art approaches.",
}

@article{ren2020simple,
  title={A Simple Fix for Convolutional Neural Network via Coordinate Embedding},
  author={Ren, Liliang and Hao, Zhuonan},
  journal={preprint},
  year={2020},
  abbr = {preprint}
}

@article{ren2019rongba,
  title={RoNGBa: A Robustly Optimized Natural Gradient Boosting Training Approach with Leaf Number Clipping},
  author={Ren, Liliang and Sun, Gen and Wu, Jiaman},
  journal={preprint},
  year={2019},
  abbr = {preprint}
}


